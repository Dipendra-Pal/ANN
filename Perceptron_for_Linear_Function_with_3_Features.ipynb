{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6wOWCaz9lSSXKwGTZdwmw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dipendra-Pal/ANN/blob/main/Perceptron_for_Linear_Function_with_3_Features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6IUHQUDv_RV"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perceptron class for linear function with n features\n",
        "class PerceptronLinear:\n",
        "    def __init__(self, learning_rate=0.01, n_inputs=4):\n",
        "        self.weights = np.random.uniform(-1, 1, n_inputs)\n",
        "        self.bias = np.random.uniform(-1, 1)\n",
        "        self.lr = learning_rate\n",
        "\n",
        "    def activation(self, x):\n",
        "        return x  # Linear activation (identity function)\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
        "        return self.activation(weighted_sum)\n",
        "\n",
        "    def train(self, X, y, max_epochs=100):\n",
        "        print(f\"\\nTraining Perceptron for {len(self.weights)}-feature linear function...\")\n",
        "        print(f\"Initial weights: {self.weights.round(4)}, Initial bias: {self.bias:.4f}\")\n",
        "\n",
        "        for epoch in range(max_epochs):\n",
        "            mse = 0\n",
        "            weight_updates = np.zeros_like(self.weights)  # Track weight changes\n",
        "            bias_update = 0\n",
        "\n",
        "            for inputs, target in zip(X, y):\n",
        "                prediction = self.predict(inputs)\n",
        "                error = target - prediction\n",
        "\n",
        "                # Accumulate updates\n",
        "                weight_updates += self.lr * error * inputs\n",
        "                bias_update += self.lr * error\n",
        "                mse += error ** 2\n",
        "\n",
        "            # Apply updates\n",
        "            self.weights += weight_updates\n",
        "            self.bias += bias_update\n",
        "\n",
        "            mse = mse / len(y)\n",
        "            print(f\"Epoch {epoch + 1}: Weights: {self.weights.round(4)}, Bias: {self.bias:.4f}, \"\n",
        "                  f\"MSE: {mse:.4f}, Weight Updates: {np.abs(weight_updates).sum():.4f}\")\n",
        "\n",
        "            # Early stopping if MSE is small\n",
        "            if mse < 1e-4:\n",
        "                print(f\"Converged after {epoch + 1} epochs\")\n",
        "                break\n",
        "\n",
        "        return self.weights, self.bias"
      ],
      "metadata": {
        "id": "9nBmJ1xowNgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate dataset for n features\n",
        "def generate_dataset(n_features, n_samples=10, bias=5):\n",
        "    np.random.seed(42)  # For reproducibility\n",
        "    X = np.random.uniform(-1, 1, (n_samples, n_features))  # Random inputs in [-1, 1]\n",
        "    true_weights = np.random.uniform(-1, 1, n_features)  # Random true weights in [-1, 1]\n",
        "    y = np.dot(X, true_weights) + bias  # Target: y = w1x1 + ... + wnxn + b\n",
        "    return X, y, true_weights"
      ],
      "metadata": {
        "id": "9zCE-hzowNUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test for given number of features\n",
        "def train_and_test(n_features):\n",
        "    # Generate data\n",
        "    X, y, true_weights = generate_dataset(n_features)\n",
        "    print(f\"\\n=== {n_features}-Feature Linear Function ===\")\n",
        "    print(f\"True weights: {true_weights.round(4)}, True bias: 5.0000\")"
      ],
      "metadata": {
        "id": "keJs0orvwNC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Perceptron\n",
        "perceptron = PerceptronLinear(learning_rate=0.01, n_inputs=n_features)\n",
        "final_weights, final_bias = perceptron.train(X, y)\n",
        "print(f\"\\nFinal Weights: {final_weights.round(4)}\")\n",
        "print(f\"Final Bias: {final_bias:.4f}\")"
      ],
      "metadata": {
        "id": "mq7wUU1-0qyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Verify predictions\n",
        "    print(\"\\nVerification of predictions:\")\n",
        "    for i, (inputs, target) in enumerate(zip(X, y)):\n",
        "        pred = perceptron.predict(inputs)\n",
        "        print(f\"Sample {i+1}: Inputs: {inputs.round(4)}, Target: {target:.4f}, \"\n",
        "              f\"Predicted: {pred:.4f}, Error: {abs(target - pred):.4f}\")"
      ],
      "metadata": {
        "id": "LnzS3f1U0uUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test for n=4 and n=5\n",
        "if __name__ == \"__main__\":\n",
        "    for n in [4, 5]:\n",
        "        train_and_test(n)"
      ],
      "metadata": {
        "id": "gh9L28wd0ymy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
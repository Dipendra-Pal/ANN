{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCsXd5CmaAPUcgKEy+OsTB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dipendra-Pal/ANN/blob/main/Perceptron_for_n_Input_Basic_Gates_(AND_OR).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "crvpE0trtqbY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perceptron class\n",
        "class Perceptron:\n",
        "    def __init__(self, learning_rate=0.1, n_inputs=2):\n",
        "        self.weights = np.random.rand(n_inputs)\n",
        "        self.bias = np.random.rand(1)\n",
        "        self.lr = learning_rate\n",
        "\n",
        "    def activation(self, x):\n",
        "        return 1 if x >= 0 else 0\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
        "        return self.activation(weighted_sum)\n",
        "\n",
        "    def train(self, X, y, max_epochs=100):\n",
        "        print(f\"\\nTraining Perceptron for {len(self.weights)}-input gate...\")\n",
        "        print(f\"Initial weights: {self.weights}, Initial bias: {self.bias[0]:.4f}\")\n",
        "\n",
        "        for epoch in range(max_epochs):\n",
        "            error_count = 0\n",
        "            for inputs, target in zip(X, y):\n",
        "                prediction = self.predict(inputs)\n",
        "                error = target - prediction\n",
        "\n",
        "                if error != 0:\n",
        "                    error_count += 1\n",
        "                    self.weights += self.lr * error * inputs\n",
        "                    self.bias += self.lr * error\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}: Weights: {self.weights}, Bias: {self.bias[0]:.4f}, Errors: {error_count}\")\n",
        "\n",
        "            if error_count == 0:\n",
        "                print(f\"Converged after {epoch + 1} epochs\")\n",
        "                break\n",
        "\n",
        "        return self.weights, self.bias\n",
        "\n",
        "    def accuracy(self, X, y):\n",
        "        correct = 0\n",
        "        for inputs, target in zip(X, y):\n",
        "            prediction = self.predict(inputs)\n",
        "            if prediction == target:\n",
        "                correct += 1\n",
        "        return correct / len(y)"
      ],
      "metadata": {
        "id": "ApoMcZdtuRje"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate truth table for n inputs\n",
        "def generate_truth_table(n_inputs):\n",
        "    X = np.array(list(itertools.product([0, 1], repeat=n_inputs)))\n",
        "    y_and = np.array([1 if np.all(x == 1) else 0 for x in X])\n",
        "    y_or = np.array([1 if np.any(x == 1) else 0 for x in X])\n",
        "    return X, y_and, y_or"
      ],
      "metadata": {
        "id": "rFKGxMqmuRYQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test for given number of inputs\n",
        "def train_and_test(n_inputs):\n",
        "    # Generate data\n",
        "    X, y_and, y_or = generate_truth_table(n_inputs)\n",
        "\n",
        "    # Train for AND gate\n",
        "    print(f\"\\n=== {n_inputs}-Input AND Gate ===\")\n",
        "    and_perceptron = Perceptron(learning_rate=0.1, n_inputs=n_inputs)\n",
        "    final_weights_and, final_bias_and = and_perceptron.train(X, y_and)\n",
        "    accuracy_and = and_perceptron.accuracy(X, y_and)\n",
        "    print(f\"\\nFinal Weights for AND: {final_weights_and}\")\n",
        "    print(f\"Final Bias for AND: {final_bias_and[0]:.4f}\")\n",
        "    print(f\"Accuracy for AND: {accuracy_and * 100:.2f}%\")\n",
        "    # Train for OR gate\n",
        "    print(f\"\\n=== {n_inputs}-Input OR Gate ===\")\n",
        "    or_perceptron = Perceptron(learning_rate=0.1, n_inputs=n_inputs)\n",
        "    final_weights_or, final_bias_or = or_perceptron.train(X, y_or)\n",
        "    accuracy_or = or_perceptron.accuracy(X, y_or)\n",
        "    print(f\"\\nFinal Weights for OR: {final_weights_or}\")\n",
        "    print(f\"Final Bias for OR: {final_bias_or[0]:.4f}\")\n",
        "    print(f\"Accuracy for OR: {accuracy_or * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "x6QAvwOYuQ_M"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test for n=3 and n=4\n",
        "if __name__ == \"__main__\":\n",
        "    for n in [3, 4]:\n",
        "        train_and_test(n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWU26xKbus6v",
        "outputId": "6f9fa85e-078b-4eb2-efae-89151496191a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 3-Input AND Gate ===\n",
            "\n",
            "Training Perceptron for 3-input gate...\n",
            "Initial weights: [0.33471296 0.62132682 0.14890867], Initial bias: 0.1097\n",
            "Epoch 1: Weights: [0.23471296 0.42132682 0.04890867], Bias: -0.3903, Errors: 7\n",
            "Epoch 2: Weights: [0.23471296 0.32132682 0.14890867], Bias: -0.4903, Errors: 3\n",
            "Epoch 3: Weights: [0.23471296 0.32132682 0.24890867], Bias: -0.4903, Errors: 2\n",
            "Epoch 4: Weights: [0.23471296 0.22132682 0.14890867], Bias: -0.5903, Errors: 1\n",
            "Epoch 5: Weights: [0.23471296 0.22132682 0.14890867], Bias: -0.5903, Errors: 0\n",
            "Converged after 5 epochs\n",
            "\n",
            "Final Weights for AND: [0.23471296 0.22132682 0.14890867]\n",
            "Final Bias for AND: -0.5903\n",
            "Accuracy for AND: 100.00%\n",
            "\n",
            "=== 3-Input OR Gate ===\n",
            "\n",
            "Training Perceptron for 3-input gate...\n",
            "Initial weights: [0.3417317  0.34681066 0.2082167 ], Initial bias: 0.8100\n",
            "Epoch 1: Weights: [0.3417317  0.34681066 0.2082167 ], Bias: 0.7100, Errors: 1\n",
            "Epoch 2: Weights: [0.3417317  0.34681066 0.2082167 ], Bias: 0.6100, Errors: 1\n",
            "Epoch 3: Weights: [0.3417317  0.34681066 0.2082167 ], Bias: 0.5100, Errors: 1\n",
            "Epoch 4: Weights: [0.3417317  0.34681066 0.2082167 ], Bias: 0.4100, Errors: 1\n",
            "Epoch 5: Weights: [0.3417317  0.34681066 0.2082167 ], Bias: 0.3100, Errors: 1\n",
            "Epoch 6: Weights: [0.3417317  0.34681066 0.2082167 ], Bias: 0.2100, Errors: 1\n",
            "Epoch 7: Weights: [0.3417317  0.34681066 0.2082167 ], Bias: 0.1100, Errors: 1\n",
            "Epoch 8: Weights: [0.3417317  0.34681066 0.2082167 ], Bias: 0.0100, Errors: 1\n",
            "Epoch 9: Weights: [0.3417317  0.34681066 0.2082167 ], Bias: -0.0900, Errors: 1\n",
            "Epoch 10: Weights: [0.3417317  0.34681066 0.2082167 ], Bias: -0.0900, Errors: 0\n",
            "Converged after 10 epochs\n",
            "\n",
            "Final Weights for OR: [0.3417317  0.34681066 0.2082167 ]\n",
            "Final Bias for OR: -0.0900\n",
            "Accuracy for OR: 100.00%\n",
            "\n",
            "=== 4-Input AND Gate ===\n",
            "\n",
            "Training Perceptron for 4-input gate...\n",
            "Initial weights: [0.06536966 0.33444858 0.34545937 0.62360013], Initial bias: 0.0965\n",
            "Epoch 1: Weights: [0.16536966 0.13444858 0.14545937 0.32360013], Bias: -0.5035, Errors: 8\n",
            "Epoch 2: Weights: [0.26536966 0.13444858 0.14545937 0.32360013], Bias: -0.5035, Errors: 2\n",
            "Epoch 3: Weights: [0.36536966 0.13444858 0.14545937 0.32360013], Bias: -0.5035, Errors: 2\n",
            "Epoch 4: Weights: [0.36536966 0.13444858 0.04545937 0.22360013], Bias: -0.6035, Errors: 3\n",
            "Epoch 5: Weights: [0.36536966 0.23444858 0.04545937 0.22360013], Bias: -0.6035, Errors: 2\n",
            "Epoch 6: Weights: [0.36536966 0.33444858 0.04545937 0.22360013], Bias: -0.6035, Errors: 2\n",
            "Epoch 7: Weights: [0.26536966 0.33444858 0.04545937 0.12360013], Bias: -0.7035, Errors: 3\n",
            "Epoch 8: Weights: [0.26536966 0.33444858 0.14545937 0.12360013], Bias: -0.7035, Errors: 2\n",
            "Epoch 9: Weights: [0.26536966 0.33444858 0.24545937 0.12360013], Bias: -0.7035, Errors: 2\n",
            "Epoch 10: Weights: [0.26536966 0.33444858 0.34545937 0.12360013], Bias: -0.7035, Errors: 2\n",
            "Epoch 11: Weights: [0.36536966 0.33444858 0.34545937 0.12360013], Bias: -0.7035, Errors: 2\n",
            "Epoch 12: Weights: [0.36536966 0.23444858 0.24545937 0.12360013], Bias: -0.8035, Errors: 3\n",
            "Epoch 13: Weights: [0.36536966 0.23444858 0.24545937 0.22360013], Bias: -0.8035, Errors: 2\n",
            "Epoch 14: Weights: [0.36536966 0.33444858 0.24545937 0.22360013], Bias: -0.8035, Errors: 2\n",
            "Epoch 15: Weights: [0.36536966 0.43444858 0.24545937 0.22360013], Bias: -0.8035, Errors: 2\n",
            "Epoch 16: Weights: [0.36536966 0.33444858 0.14545937 0.12360013], Bias: -0.9035, Errors: 1\n",
            "Epoch 17: Weights: [0.36536966 0.33444858 0.14545937 0.12360013], Bias: -0.9035, Errors: 0\n",
            "Converged after 17 epochs\n",
            "\n",
            "Final Weights for AND: [0.36536966 0.33444858 0.14545937 0.12360013]\n",
            "Final Bias for AND: -0.9035\n",
            "Accuracy for AND: 100.00%\n",
            "\n",
            "=== 4-Input OR Gate ===\n",
            "\n",
            "Training Perceptron for 4-input gate...\n",
            "Initial weights: [0.63315411 0.92062417 0.00358548 0.14997802], Initial bias: 0.6675\n",
            "Epoch 1: Weights: [0.63315411 0.92062417 0.00358548 0.14997802], Bias: 0.5675, Errors: 1\n",
            "Epoch 2: Weights: [0.63315411 0.92062417 0.00358548 0.14997802], Bias: 0.4675, Errors: 1\n",
            "Epoch 3: Weights: [0.63315411 0.92062417 0.00358548 0.14997802], Bias: 0.3675, Errors: 1\n",
            "Epoch 4: Weights: [0.63315411 0.92062417 0.00358548 0.14997802], Bias: 0.2675, Errors: 1\n",
            "Epoch 5: Weights: [0.63315411 0.92062417 0.00358548 0.14997802], Bias: 0.1675, Errors: 1\n",
            "Epoch 6: Weights: [0.63315411 0.92062417 0.00358548 0.14997802], Bias: 0.0675, Errors: 1\n",
            "Epoch 7: Weights: [0.63315411 0.92062417 0.10358548 0.14997802], Bias: 0.0675, Errors: 2\n",
            "Epoch 8: Weights: [0.63315411 0.92062417 0.10358548 0.14997802], Bias: -0.0325, Errors: 1\n",
            "Epoch 9: Weights: [0.63315411 0.92062417 0.10358548 0.14997802], Bias: -0.0325, Errors: 0\n",
            "Converged after 9 epochs\n",
            "\n",
            "Final Weights for OR: [0.63315411 0.92062417 0.10358548 0.14997802]\n",
            "Final Bias for OR: -0.0325\n",
            "Accuracy for OR: 100.00%\n"
          ]
        }
      ]
    }
  ]
}